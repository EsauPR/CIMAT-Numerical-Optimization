\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@beforestart
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Métodología}{1}{section.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Descenso de Gradiente}}{1}{algocf.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Método de Newton}}{1}{algocf.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Resultados}{2}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Obtención del minimizador para la función con $\lambda =1$, se observa una buena aproximación sobre los la serie formada por el vector Y.}}{2}{figure.1}\protected@file@percent }
\newlabel{fignl1}{{1}{2}{Obtención del minimizador para la función con $\lambda =1$, se observa una buena aproximación sobre los la serie formada por el vector Y}{figure.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Método de Newton con $\alpha =1$}}{2}{table.1}\protected@file@percent }
\newlabel{tabn}{{I}{2}{Método de Newton con $\alpha =1$}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Obtención del minimizador para la función con $\lambda =100$, se observa un suavizado provocado por el contribución de $\lambda $.}}{2}{figure.2}\protected@file@percent }
\newlabel{fignl100}{{2}{2}{Obtención del minimizador para la función con $\lambda =100$, se observa un suavizado provocado por el contribución de $\lambda $}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Obtención del minimizador para la función con $\lambda =1000$, el suavizado de los la serie de los valores de Y es más intenso.}}{2}{figure.3}\protected@file@percent }
\newlabel{fignl1000}{{3}{2}{Obtención del minimizador para la función con $\lambda =1000$, el suavizado de los la serie de los valores de Y es más intenso}{figure.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Descenso de Gradiente con $\alpha $ Autoadaptable}}{2}{table.2}\protected@file@percent }
\newlabel{tabg1}{{II}{2}{Descenso de Gradiente con $\alpha $ Autoadaptable}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Descenso de Gradiente con $\alpha $ Fijo}}{2}{table.3}\protected@file@percent }
\newlabel{tabg2}{{III}{2}{Descenso de Gradiente con $\alpha $ Fijo}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Descenso de Gradiente con $\alpha $ mediante Backtracking}}{3}{table.4}\protected@file@percent }
\newlabel{tabg3}{{IV}{3}{Descenso de Gradiente con $\alpha $ mediante Backtracking}{table.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusiones}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Apéndice}{3}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Problemas}{3}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Para problema 1. De azul la función $f(x_1. x_2) = (x_1, x_2^2)^2$, de negro todos los puntos de la forma ($-x_2^2, x_2$) que minimizan a $f$.}}{3}{figure.4}\protected@file@percent }
\newlabel{fig1}{{4}{3}{Para problema 1. De azul la función $f(x_1. x_2) = (x_1, x_2^2)^2$, de negro todos los puntos de la forma ($-x_2^2, x_2$) que minimizan a $f$}{figure.4}{}}
\bibcite{b1}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Algoritmo para actualización de tamaño de paso Backtracking}{4}{subsection.5.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Método de Backtracking para tamaño de paso}}{4}{algocf.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Gradiente y Hessiano de la función a minimizar}{4}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-D}}Gráficos Usando el Método de Descenso de Gradiente}{4}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Obtención del minimizador para la función con $\lambda =1$, el suavizado de los la serie de los valores de Y es más intenso.}}{4}{figure.5}\protected@file@percent }
\newlabel{figdl1}{{5}{4}{Obtención del minimizador para la función con $\lambda =1$, el suavizado de los la serie de los valores de Y es más intenso}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Obtención del minimizador para la función con $\lambda =100$, el suavizado de los la serie de los valores de Y es más intenso.}}{5}{figure.6}\protected@file@percent }
\newlabel{figdl100}{{6}{5}{Obtención del minimizador para la función con $\lambda =100$, el suavizado de los la serie de los valores de Y es más intenso}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Obtención del minimizador para la función con $\lambda =1000$, el suavizado de los la serie de los valores de Y es más intenso.}}{5}{figure.7}\protected@file@percent }
\newlabel{figdl1000}{{7}{5}{Obtención del minimizador para la función con $\lambda =1000$, el suavizado de los la serie de los valores de Y es más intenso}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{Referencias}{5}{section*.5}\protected@file@percent }
